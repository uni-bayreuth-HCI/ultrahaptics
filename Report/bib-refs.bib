@misc{babel7.15,
mendeley-groups = {Mid-Haptics},
title = {{Babel {\textperiodcentered} The compiler for next generation JavaScript}},
url = {https://babeljs.io/},
urldate = {2021-10-09}
},
@misc{spotify-coordinator,
mendeley-groups = {Mid-Haptics},
title = {{GitHub - spotify/coordinator: A visual interface for turning an SVG into XY co{\"{o}}rdinates.}},
url = {https://github.com/spotify/coordinator},
urldate = {2021-10-09}
},

@misc{Ultrahaptics-APIs,
mendeley-groups = {Mid-Haptics},
title = {{Using Ultrahaptics APIs: Amplitude Modulation and Time Point Streaming – Ultrahaptics Developer Information}},
url = {https://developer.ultrahaptics.com/knowledgebase/ultrahaptics-apis/},
urldate = {2021-10-09}
}

@Article{s130506380,
AUTHOR = {Weichert, Frank and Bachmann, Daniel and Rudak, Bartholomäus and Fisseler, Denis},
TITLE = {Analysis of the Accuracy and Robustness of the Leap Motion Controller},
JOURNAL = {Sensors},
VOLUME = {13},
YEAR = {2013},
NUMBER = {5},
PAGES = {6380--6393},
URL = {https://www.mdpi.com/1424-8220/13/5/6380},
PubMedID = {23673678},
ISSN = {1424-8220},
ABSTRACT = {The Leap Motion Controller is a new device for hand gesture controlled user interfaces with declared sub-millimeter accuracy. However, up to this point its capabilities in real environments have not been analyzed. Therefore, this paper presents a first study of a Leap Motion Controller. The main focus of attention is on the evaluation of the accuracy and repeatability. For an appropriate evaluation, a novel experimental setup was developed making use of an industrial robot with a reference pen allowing a position accuracy of 0.2 mm. Thereby, a deviation between a desired 3D position and the average measured positions below 0.2mmhas been obtained for static setups and of 1.2mmfor dynamic setups. Using the conclusion of this analysis can improve the development of applications for the Leap Motion controller in the field of Human-Computer Interaction.},
DOI = {10.3390/s130506380}
},
@misc{leap-controller,
mendeley-groups = {Mid-Haptics},
title = {{Controller — Leap Motion JavaScript SDK v3.2 Beta documentation}},
url = {https://developer-archive.leapmotion.com/documentation/javascript/api/Leap.Controller.html},
urldate = {2021-10-10}
},

@book{iwamoto2008non,
	title={Non-contact method for producing tactile sensation using airborne ultrasound},
	author={Iwamoto, Takayuki and Tatezono, Mari and Shinoda, Hiroyuki},
	booktitle={International Conference on Human Haptic Sensing and Touch Enabled Computer Applications},
	pages={504--513},
	year={2008},
	organization={Springer}
}

@misc{ul,
	mendeley-groups = {Mid Air Haptics},
	title = {{Digital worlds that feel human | Ultraleap}},
	url = {https://www.ultraleap.com/},
	urldate = {2021-10-09}
}

@misc{ultraviz,
	mendeley-groups = {Mid Air Haptics},
	title = {{ultraleap-labs/Ultraviz at master {\textperiodcentered} ultraleap/ultraleap-labs {\textperiodcentered} GitHub}},
	url = {https://github.com/ultraleap/ultraleap-labs/tree/master/Ultraviz},
	urldate = {2021-10-09}
}

@misc{oil,
	mendeley-groups = {Mid Air Haptics},
	title = {{How does Ultrahaptics technology work? – Ultrahaptics Developer Information}},
	url = {https://developer.ultrahaptics.com/knowledgebase/haptics-overview/},
	urldate = {2021-10-10}
}
@article{Hajas2020,
abstract = {An important challenge that affects ultrasonic mid-air haptics, in contrast to physical touch, is that we lose certain exploratory procedures such as contour following. This makes the task of perceiving geometric properties and shape identification more difficult. Meanwhile, the growing interest in mid-air haptics and their application to various new areas requires an improved understanding of how we perceive specific haptic stimuli, such as icons and control dials in mid-air. We address this challenge by investigating static and dynamic methods of displaying 2D geometric shapes in mid-air. We display a circle, a square, and a triangle, in either a static or dynamic condition, using ultrasonic mid-air haptics. In the static condition, the shapes are presented as a full outline in mid-air, while in the dynamic condition, a tactile pointer is moved around the perimeter of the shapes. We measure participants' accuracy and confidence of identifying shapes in two controlled experiments (n_1 = 34, n_2 = 25). Results reveal that in the dynamic condition people recognise shapes significantly more accurately, and with higher confidence. We also find that representing polygons as a set of individually drawn haptic strokes, with a short pause at the corners, drastically enhances shape recognition accuracy. Our research supports the design of mid-air haptic user interfaces in application scenarios such as in-car interactions or assistive technology in education.},
author = {Hajas, Daniel and Pittera, Dario and Nasce, Antony and Georgiou, Orestis and Obrist, Marianna},
doi = {10.1109/TOH.2020.2966445},
issn = {23294051},
journal = {IEEE Transactions on Haptics},
keywords = {Mid-air haptics,assistive technology,geometry,haptic controls,in-car interaction,memory chunking,shape perception,touch},
mendeley-groups = {Mid Air Haptics},
number = {4},
pages = {806--817},
pmid = {31940553},
title = {{Mid-Air Haptic Rendering of 2D Geometric Shapes with a Dynamic Tactile Pointer}},
volume = {13},
year = {2020}
}



